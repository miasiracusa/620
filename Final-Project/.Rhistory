library(dplyr)
library(tidyr)
library(ggplot2)
wrn <- as.data.frame(read.csv("data/nyc_wrn_db.csv"))
## data processing packages
library(tidyverse)
##formatting packages
library(knitr); library(kableExtra); library(default)
##network packages
library(igraph)
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
# load data
yelp<- read.csv("data/yelp.csv"); yelp <- select(yelp,-X, -business_id, -user_id) %>% rename(businessID = itemID)
# transform data for network analysis
yelp_network <- yelp %>%
select(userID, businessID, name, stars, latitude, longitude) %>%
group_by(businessID) %>%
add_count() %>%
rename(size = n)%>%
ungroup() %>%
group_by(userID) %>%
add_count() %>%
rename(weight = n)%>%
ungroup()
# transform data for text processing
yelp_reviews <- yelp %>%
transform(reviewID=match(review_id, unique(review_id))) %>%
select(-review_id, -longitude, -latitude) %>%
select(userID, businessID, reviewID, name, city, state, votes.funny, votes.useful, votes.cool,
stars, text, date)
yelp_network
yelp_reviews
# define edges; spread data from long to wide; convert to matrix
edges <- yelp_network %>%
select(businessID, userID, weight) %>%
spread(businessID, weight, fill = 0) %>%
column_to_rownames('userID') %>%
as.matrix()
# define nodesets
business_nodes <- yelp_network %>%
select(businessID, name, size) %>%
mutate(type = 'business', name = as.character(name)) %>%
distinct()
user_nodes <- yelp_network %>%
select(userID) %>%
mutate(name=paste0("U",userID),sizes = NA, type = 'user') %>%
distinct()
# bind rows
nodes <- bind_rows(business_nodes,user_nodes)
# initiate graph from matrix
g <- graph_from_incidence_matrix(edges, weighted=T)
# Define vertex color/shape
V(g)$shape <- ifelse(V(g)$type, "circle", "square")
V(g)$color <- ifelse(V(g)$type, "red", "white")
# Plot network
plot.igraph(g,
layout=layout.bipartite,
vertex.frame.color="black",
vertex.label=NA)
# verify vertices (F = User; T = Business)
node_count <-table(V(g)$type==T)
# Verify connections
rbind(Business.Nodes = toString(node_count[2]),
User.Nodes = toString(node_count[1]),
Is.Weighted = toString(is.weighted(g)),
Is.Bipartite = toString(is.bipartite(g))) %>%
kable(caption="Verify Node Counts and Connectivity") %>%
kable_styling()
#In order to see our network better, we are going to sparsify it by only keeping only the most important ties and discarding the rest
#Modify data frame
edgesDf <- yelp_network %>%
select(businessID, userID, weight)
#Convert weight to numeric
weight <- as.numeric(unlist(edgesDf$weight))
head(edgesDf)
#Examine frquency of weight
hist(weight)
#Calculate mean and standard deviation
mean(weight)
sd(weight)
#Keep edges that have weight higher than the mean
cut.off <- mean(weight)
net.sp <- delete_edges(g, E(g)[weight<cut.off])
plot(net.sp)
##network packages
library(igraph)
## text processing packages
library(tidyverse); library(stringr); library(tidytext); library(textdata)
install.packages('tidytext')
##network packages
library(igraph)
## text processing packages
library(tidyverse); library(stringr); library(tidytext); library(textdata)
##network packages
library(igraph)
## text processing packages
library(tidyverse); library(stringr); library(tidytext); library(textdata)
install.packages('textdata')
##network packages
library(igraph)
## text processing packages
library(tidyverse); library(stringr); library(tidytext); library(textdata)
##formatting packages
library(knitr); library(kableExtra); library(default)
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
# load data
yelp<- read.csv("data/yelp.csv"); yelp <- select(yelp,-X, -business_id, -user_id) %>% rename(businessID = itemID)
# transform data for network analysis
yelp_network <- yelp %>%
select(userID, businessID, name, stars, latitude, longitude) %>%
group_by(businessID) %>%
add_count() %>%
rename(size = n)%>%
ungroup() %>%
group_by(userID) %>%
add_count() %>%
rename(weight = n)%>%
ungroup()
# transform data for text processing
yelp_reviews <- yelp %>%
transform(reviewID=match(review_id, unique(review_id))) %>%
select(-review_id, -longitude, -latitude) %>%
select(userID, businessID, reviewID, name, city, state, votes.funny, votes.useful, votes.cool,
stars, text, date)
yelp_network
yelp_reviews
# define edges; spread data from long to wide; convert to matrix
edges <- yelp_network %>%
select(businessID, userID, weight) %>%
spread(businessID, weight, fill = 0) %>%
column_to_rownames('userID') %>%
as.matrix()
# define nodesets
business_nodes <- yelp_network %>%
select(businessID, name, size) %>%
mutate(type = 'business', name = as.character(name)) %>%
distinct()
user_nodes <- yelp_network %>%
select(userID) %>%
mutate(name=paste0("U",userID),sizes = NA, type = 'user') %>%
distinct()
# bind rows
nodes <- bind_rows(business_nodes,user_nodes)
# initiate graph from matrix
g <- graph_from_incidence_matrix(edges, weighted=T)
# Define vertex color/shape
V(g)$shape <- ifelse(V(g)$type, "circle", "square")
V(g)$color <- ifelse(V(g)$type, "red", "white")
# Plot network
plot.igraph(g,
layout=layout.bipartite,
vertex.frame.color="black",
vertex.label=NA)
# verify vertices (F = User; T = Business)
node_count <-table(V(g)$type==T)
# Verify connections
rbind(Business.Nodes = toString(node_count[2]),
User.Nodes = toString(node_count[1]),
Is.Weighted = toString(is.weighted(g)),
Is.Bipartite = toString(is.bipartite(g))) %>%
kable(caption="Verify Node Counts and Connectivity") %>%
kable_styling()
#In order to see our network better, we are going to sparsify it by only keeping only the most important ties and discarding the rest
#Modify data frame
edgesDf <- yelp_network %>%
select(businessID, userID, weight)
#Convert weight to numeric
weight <- as.numeric(unlist(edgesDf$weight))
head(edgesDf)
#Examine frquency of weight
hist(weight)
#Calculate mean and standard deviation
mean(weight)
sd(weight)
#Keep edges that have weight higher than the mean
cut.off <- mean(weight)
net.sp <- delete_edges(g, E(g)[weight<cut.off])
plot(net.sp)
m <- get_sentiments("bing")
pos.words <- vector()
neg.words <- vector()
for (i in 1:nrow(m)) {
if (m$sentiment[i] == "positive") {
pos.words[i] <- m$word[i]
}
}
pos.words
for (i in 1:nrow(m)) {
if (m$sentiment[i] == "negative") {
neg.words[i] <- m$word[i]
}
}
neg.words
v <- as.character(as.vector(yelp_review$text))
# positive / negative sentiment function
m <- get_sentiments("bing")
pos.words <- vector()
neg.words <- vector()
for (i in 1:nrow(m)) {
if (m$sentiment[i] == "positive") {
pos.words[i] <- m$word[i]
}
}
pos.words
for (i in 1:nrow(m)) {
if (m$sentiment[i] == "negative") {
neg.words[i] <- m$word[i]
}
}
neg.words[5]
v <- as.character(as.vector(yelp_reviews$text))
score.sentiment = function(v, pos.words, neg.words, .progress = "none") {
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list or a vector as an
# “l” for us we want a simple array (“a”) of scores back, so we use “l” +
# “a” + “ply” = “laply”:
scores = laply(v, function(sentence, pos.words, neg.words) {
# clean up sentences with R’s regex-driven global substitute, gsub():
sentence = gsub("[[:punct:]]", "", sentence)
sentence = gsub("[[:cntrl:]]", "", sentence)
sentence = gsub("\\d+", "", sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, "\\s+")
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA we just want a
# TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress = .progress)
scores.df = data.frame(score = scores, text = v)
return(scores.df)
}
t <- score.sentiment(v, pos.words, neg.words)
full <- inner_join(t, yelp_reviews, by = "text")
t <- score.sentiment(v, pos.words, neg.words)
full <- inner_join(t, yelp_reviews, by = "text")
##network packages
library(igraph)
## text processing packages
library(plyr);library(dplyr); library(tidyr); library(stringr); library(tidytext); library(textdata)
##formatting packages
library(knitr); library(kableExtra); library(default)
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
##network packages
library(igraph)
## text processing packages
library(plyr);library(dplyr); library(tidyverse); library(stringr); library(tidytext); library(textdata)
##formatting packages
library(knitr); library(kableExtra); library(default)
## knit sizing
options(max.print="100"); opts_knit$set(width=75)
## augment chunk output
opts_chunk$set(echo=T,cache=F, tidy=T,comment=F,message=T,warning=T) #change message/warning to F upon completion
## set table style for consistency
default(kable) <- list(format="html")
default(kable_styling)  <- list(bootstrap_options = "hover",full_width=T, font_size=10)
default(scroll_box) <- list(width = "100%")
