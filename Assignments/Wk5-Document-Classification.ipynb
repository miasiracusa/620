{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data 620 - Assignment 6<br>July 10, 2019<br>Team 2: <ul> <li>Anthony Munoz</li> <li>Katie Evers</li> <li>Juliann McEachern</li> <li>Mia Siracusa</li></ul>\n",
    "<h1 align=\"center\">\"Document Classification\"</h1>\n",
    "\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  \n",
    "\n",
    "Here is one example of such data:  [UCI Machine Learning Repository: Spambase Data Set](http://archive.ics.uci.edu/ml/datasets/Spambase).\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "This assignment is due end of day on Wednesday, July 10th.  You may work in a small team if you want.\n",
    "\n",
    "*NOTE: This is a two week assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ham = '/Users/Anthony/Desktop/School/MS/DATA-620/github/620/Assignments/data/ham/ham/'\n",
    "email_list = os.listdir(path_ham)\n",
    "path_spam = '/Users/Anthony/Desktop/School/MS/DATA-620/github/620/Assignments/data/spam/spam/'\n",
    "email_list_spam = os.listdir(path_spam)\n",
    "mylist = []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Uploading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://github.com/Anth350z/620/tree/master/Assignments/data/ham/ham'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-4bbb51927384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The path for the ham and spam emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath_ham\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/Anth350z/620/tree/master/Assignments/data/ham/ham'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0memail_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_ham\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpath_spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/Anth350z/620/tree/master/Assignments/data/spam/spam/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memail_list_spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_spam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/Anth350z/620/tree/master/Assignments/data/ham/ham'"
     ]
    }
   ],
   "source": [
    "#The path for the ham and spam emails\n",
    "path_ham = 'https://github.com/Anth350z/620/tree/master/Assignments/data/ham/ham'\n",
    "email_list = os.listdir(path_ham)\n",
    "path_spam = 'https://github.com/Anth350z/620/tree/master/Assignments/data/spam/spam/'\n",
    "email_list_spam = os.listdir(path_spam)\n",
    "mylist = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-cfa750edcc5e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-cfa750edcc5e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    require 'net/http'\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#require 'open-uri'\n",
    "require 'net/http'\n",
    "\n",
    "uri = \"https://raw.githubusercontent.com/Anth350z/620/tree/master/Assignments/data/spam/spam/\"\n",
    "uri = URI(uri)\n",
    "file = Net::HTTP.get(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to append the emails together on the list\n",
    "def loading_data(email_type,mylist,path,email_list):\n",
    "    #print(email_type,mylist,path,email_list)\n",
    "    for i in email_list:\n",
    "        with open(path + i , 'r', encoding=\"ISO-8859-1\") as file:\n",
    "           mylist.append([email_type , file.read()])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_data(\"ham\",mylist,path_ham,email_list)\n",
    "loading_data(\"spam\",mylist,path_spam,email_list_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2798"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list length information\n",
    "len(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list to a dataframe with pandas\n",
    "df_all = pd.DataFrame(mylist)\n",
    "df_all.columns = [\"label\",\"email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>From rpm-list-admin@freshrpms.net  Mon Jul 22 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>From webmake-talk-admin@lists.sourceforge.net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>From fork-admin@xent.com  Wed Aug 14 11:01:15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>From ilug-admin@linux.ie  Mon Jul 22 19:50:20 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>From razor-users-admin@lists.sourceforge.net  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                              email\n",
       "0   ham  From rpm-list-admin@freshrpms.net  Mon Jul 22 ...\n",
       "1   ham  From webmake-talk-admin@lists.sourceforge.net ...\n",
       "2   ham  From fork-admin@xent.com  Wed Aug 14 11:01:15 ...\n",
       "3   ham  From ilug-admin@linux.ie  Mon Jul 22 19:50:20 ...\n",
       "4   ham  From razor-users-admin@lists.sourceforge.net  ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (Stemmer/Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = stem.SnowballStemmer('english')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function lower the data, stem and use stopwords for cleaning and organize the data.\n",
    "def data_cleaning(data):\n",
    "    data = data.lower()\n",
    "    data = [message_word for message_word  in data.split() if message_word  not in stopwords]\n",
    "    data = \" \".join([stemmer.stem(message_word ) for message_word  in data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we call the function to apply some cleaning \n",
    "df_all['email'] = df_all['email'].apply(data_cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>rpm-list-admin@freshrpms.net mon jul 22 17:57:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>webmake-talk-admin@lists.sourceforge.net tue a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>fork-admin@xent.com wed aug 14 11:01:15 2002 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>ilug-admin@linux.i mon jul 22 19:50:20 2002 re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>razor-users-admin@lists.sourceforge.net fri au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                              email\n",
       "0   ham  rpm-list-admin@freshrpms.net mon jul 22 17:57:...\n",
       "1   ham  webmake-talk-admin@lists.sourceforge.net tue a...\n",
       "2   ham  fork-admin@xent.com wed aug 14 11:01:15 2002 r...\n",
       "3   ham  ilug-admin@linux.i mon jul 22 19:50:20 2002 re...\n",
       "4   ham  razor-users-admin@lists.sourceforge.net fri au..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Data 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we prepare and split the data for atrining \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "email = df_all['email'].values\n",
    "label = df_all['label'].values\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                       stop_words='english')\n",
    "email = vectorizer.fit_transform(email)\n",
    "\n",
    "#training the data splitting with 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(email,label,test_size=0.2, shuffle=True,random_state=0,  stratify=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9857015192135835\n",
      " Testing Accuracy: 0.9803571428571428\n"
     ]
    }
   ],
   "source": [
    "#after the data is train we use the naive bayes for prediction model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy: \" + str(clf.score(X_train, y_train)))\n",
    "\n",
    "print(\" Testing Accuracy: \" + str(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9986595174262735\n",
      " Testing Accuracy: 0.9660714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RDC = RandomForestClassifier()\n",
    "RDC.fit(X_train,y_train)\n",
    "\n",
    "print(\"Training Accuracy: \" + str(RDC.score(X_train, y_train)))\n",
    "\n",
    "print(\" Testing Accuracy: \" + str(RDC.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      " Testing Accuracy: 0.9946428571428572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD = SGDClassifier()\n",
    "SGD.fit(X_train,y_train)\n",
    "print(\"Training Accuracy: \" + str(SGD.score(X_train, y_train)))\n",
    "\n",
    "print(\" Testing Accuracy: \" + str(SGD.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. https://www.datacamp.com/community/blog/text-mining-in-r-and-python-tips\n",
    "2. https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk\n",
    "3. https://towardsdatascience.com/spam-or-ham-introduction-to-natural-language-processing-part-2-a0093185aebd\n",
    "4. https://gtraskas.github.io/post/spamit/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
